import pandas as pd
import numpy as np
import re

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”¹ Utility: clean text safely
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_text(text):
    if pd.isna(text):
        return ""
    text = str(text).strip()
    text = re.sub(r"\s+", " ", text)
    return text

def normalize_type(t):
    if not isinstance(t, str):
        return "unknown"
    t = t.lower().strip()
    mapping = {
        "movie": "movie",
        "movies": "movie",
        "film": "movie",
        "tv show": "series",
        "series": "series",
        "tv series": "series",
        "show": "series",
        "anime": "anime",
        "animes": "anime",
        "cartoon": "anime"
    }
    return mapping.get(t, "unknown")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“¥ Load datasets
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
unified = pd.read_csv("data/unified_content_cleaned.csv")
dataset = pd.read_csv("data/dataset.csv")

# Ensure consistent columns
unified.columns = unified.columns.str.lower().str.strip()
dataset.columns = dataset.columns.str.lower().str.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§© Normalize common columns
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# For unified
if "overview" in unified.columns:
    unified.rename(columns={"overview": "description"}, inplace=True)
if "vote_average" in unified.columns:
    unified.rename(columns={"vote_average": "rating"}, inplace=True)

# For dataset
if "overview" in dataset.columns:
    dataset.rename(columns={"overview": "description"}, inplace=True)
if "vote_average" in dataset.columns:
    dataset.rename(columns={"vote_average": "rating"}, inplace=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ Minimal column set alignment
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
base_columns = ["title", "type", "genre", "description", "rating", "release_date"]

for df in [unified, dataset]:
    for col in base_columns:
        if col not in df.columns:
            df[col] = np.nan
    df = df[base_columns]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ¨ Clean and Normalize
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for df in [unified, dataset]:
    df["title"] = df["title"].apply(clean_text).str.lower()
    df["genre"] = df["genre"].apply(clean_text)
    df["description"] = df["description"].apply(clean_text)
    df["type"] = df["type"].apply(normalize_type)

# Remove empty titles
unified = unified[unified["title"].notna() & (unified["title"].str.strip() != "")]
dataset = dataset[dataset["title"].notna() & (dataset["title"].str.strip() != "")]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ” Merge + Deduplicate
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
merged = pd.concat([unified, dataset], ignore_index=True)
merged.drop_duplicates(subset=["title", "type"], keep="first", inplace=True)

# Handle missing ratings
merged["rating"] = pd.to_numeric(merged["rating"], errors="coerce").fillna(0)

# Ensure type consistency
merged["type"] = merged["type"].apply(normalize_type)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“… Extract Year
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "release_date" in merged.columns:
    merged["year"] = pd.to_datetime(merged["release_date"], errors="coerce").dt.year.fillna(0).astype(int)
else:
    merged["year"] = 0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… Final Cleaned Dataset
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
merged.reset_index(drop=True, inplace=True)
print(f"âœ… Merged dataset created with {len(merged)} unique titles")
print("ğŸ“Š Type distribution:")
print(merged["type"].value_counts())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ’¾ Save merged dataset
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
merged.to_csv("merged_unified_dataset.csv", index=False)
print("\nğŸ’¾ Saved as 'merged_unified_dataset.csv'")
